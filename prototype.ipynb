{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torchmetrics.functional import accuracy, precision\n",
    "import torchmetrics.functional as tf\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "\n",
    "from positional_encodings.torch_encodings import PositionalEncodingPermute2D\n",
    "\n",
    "from data.cifar100 import CIFAR100DataModule\n",
    "from data.cifar10 import CIFAR10DataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to whatever folder you wish CIFAR-100 to be downloaded into\n",
    "CIFAR = \"/media/curttigges/project-files/datasets/cifar-100/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierPositionEncoding(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalImageEmbedding(nn.Module):\n",
    "    \"\"\"Reshapes images and concatenates position encoding\n",
    "    \n",
    "    Initializes position encoding,\n",
    "    \n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels, embed_dim):\n",
    "        super().__init__()\n",
    "        self.p_enc = PositionalEncodingPermute2D(input_channels)\n",
    "        self.conv = nn.Conv1d(input_channels*2, embed_dim, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # initial x of shape [BATCH_SIZE x CHANNELS x HEIGHT x WIDTH]\n",
    "        \n",
    "        enc = p_enc(x)\n",
    "        # create position encoding of the same shape as x\n",
    "\n",
    "        x = torch.cat([x, enc], dim=1)\n",
    "        # concatenate position encoding along the channel dimension\n",
    "        # shape is now [BATCH_SIZE x COLOR_CHANNELS + POS_ENC_CHANNELS x HEIGHT x WIDTH]\n",
    "\n",
    "        x = x.flatten(2)\n",
    "        # reshape to [BATCH_SIZE x CHANNELS x HEIGHT*WIDTH]\n",
    "\n",
    "        x = self.conv(x)\n",
    "        # shape is now [BATCH_SIZE x EMBED_DIM x HEIGHT*WIDTH]\n",
    "\n",
    "        x = x.permute(2, 0, 1)\n",
    "        # shape is now [HEIGHT*WIDTH x BATCH_SIZE x EMBED_DIM]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50176, 8, 32])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_batch = torch.rand((8, 3, 224, 224))\n",
    "ip = PositionalImageEmbedding(3,32)\n",
    "res = ip(rand_batch)\n",
    "res.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceiverCrossAttention(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LatentTransformer(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceiver(nn.Module):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceiverTrainingModule(pl.LightningModule):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('cv-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "86c88f9a3588ea9343d84fb206e74c1b312a3b0d43eff9010fec7c5800ba29d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
